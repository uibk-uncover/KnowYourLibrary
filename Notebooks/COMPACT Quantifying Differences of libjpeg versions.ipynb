{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import jpeglib\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# set arbitrary/default jpeglib version\n",
    "v_arbitrary = '9e'\n",
    "jpeglib.version.set(v_arbitrary)\n",
    "\n",
    "# set subsample size\n",
    "N_samples = 10\n",
    "\n",
    "# database path\n",
    "db_path = Path.home() / 'Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-review",
   "metadata": {},
   "source": [
    "### Load ALASKA Dataset \n",
    "We only need the Alaska Dataset, since only colored images produce differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "invalid-wrist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ALASKA2 database with 80004 images.\n",
      "Input shape (1000, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load ALASKA2 dataset\n",
    "alaska_path = db_path / 'ALASKA_v2_TIFF_256_COLOR'\n",
    "alaska_names = [alaska_path / f for f in os.listdir(alaska_path)]\n",
    "print(\"Loaded ALASKA2 database with\", len(alaska_names), \"images.\")\n",
    "\n",
    "# sample without replacement\n",
    "random.seed(543)\n",
    "alaska_names_sub = random.sample(alaska_names, N_samples-2)\n",
    "#alaska_names_sub = alaska_names[:N_samples-2]\n",
    "\n",
    "# add most and least saturated images to the sample set\n",
    "alaska_names_sub.append((alaska_path / '10343.tif',98491)[0])\n",
    "alaska_names_sub.append((alaska_path / '05887.tif', 78128)[0])\n",
    "\n",
    "# save selection\n",
    "import csv\n",
    "# with open('quantification_files.csv', 'w') as fp:\n",
    "#    csv.writer(fp).writerows([[str(f).replace('/home/nora', '~')] for f in alaska_names_sub])\n",
    "# load selection\n",
    "with open('quantification_files.csv') as fp:\n",
    "    alaska_names_sub = [f[0].replace('~',str(Path.home())) for f in csv.reader(fp)]\n",
    "    \n",
    "# load the image with PIL\n",
    "alaska = np.array([plt.imread(f) for f in alaska_names_sub])\n",
    "print(\"Input shape\", alaska.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a642a2",
   "metadata": {},
   "source": [
    "## Decompression VERSIONS experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1c15e2",
   "metadata": {},
   "source": [
    "For quantification of decompression mismatch we use PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "french-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_versions(**kwargs):\n",
    "    tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "    psnr = []\n",
    "    for i in range(alaska.shape[0]):\n",
    "        # compress with arbitrary\n",
    "        with jpeglib.version(v_arbitrary):\n",
    "            if \"sf\" in kwargs:\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], samp_factor=kwargs[\"sf\"])\n",
    "            else:\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i])\n",
    "                \n",
    "        # decompress with each version\n",
    "        with jpeglib.version(kwargs[\"v1\"]):\n",
    "            if \"dct\" in kwargs:\n",
    "                x_v1 = jpeglib.JPEG(tmp.name).read_spatial(dct_method=kwargs[\"dct\"])\n",
    "            else:\n",
    "                x_v1 = jpeglib.JPEG(tmp.name).read_spatial()\n",
    "        with jpeglib.version(kwargs[\"v2\"]):\n",
    "            if \"dct\" in kwargs:\n",
    "                x_v2 = jpeglib.JPEG(tmp.name).read_spatial(dct_method=kwargs[\"dct\"])\n",
    "            else:\n",
    "                x_v2 = jpeglib.JPEG(tmp.name).read_spatial()\n",
    "        # compute psnr\n",
    "        psnr.append(PSNR(x_v1, x_v2))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italian-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_parameters(**kwargs):\n",
    "    tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "    # iterate alaska subsample\n",
    "    psnr = []\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version(v_arbitrary):\n",
    "            # compress with arbitrary\n",
    "            if \"qf1\" in kwargs:\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], qt=kwargs[\"qf1\"])\n",
    "                x1 = jpeglib.JPEG(tmp.name).read_spatial()\n",
    "                \n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], qt=kwargs[\"qf2\"])\n",
    "                x2 = jpeglib.JPEG(tmp.name).read_spatial()\n",
    "            else:\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i])\n",
    "                \n",
    "            # decompress with arbitrary\n",
    "            if \"dct1\" in kwargs:\n",
    "                x1 = jpeglib.JPEG(tmp.name).read_spatial(dct_method=kwargs[\"dct1\"])\n",
    "                x2 = jpeglib.JPEG(tmp.name).read_spatial(dct_method=kwargs[\"dct2\"])\n",
    "            \n",
    "            if \"flag1\" in kwargs:\n",
    "                x1 = jpeglib.JPEG(tmp.name).read_spatial(flags=[kwargs[\"flag1\"]])\n",
    "                x2 = jpeglib.JPEG(tmp.name).read_spatial(flags=[kwargs[\"flag2\"]])\n",
    "        # compute psnr\n",
    "        psnr.append(PSNR(x1, x2))\n",
    "    \n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "operating-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(x_ref, x_noisy):\n",
    "    \"\"\"PSNR of two signals.\"\"\"\n",
    "    D = x_ref.astype(np.float32) - x_noisy.astype(np.float32)\n",
    "    mse = (D**2).mean()\n",
    "    maxi = 255#x_ref.max().astype(np.float64)\n",
    "    return np.log10(maxi**2/mse)*10\n",
    "\n",
    "\n",
    "def get_mismatching_images_decomp(psnr):\n",
    "    psrn = np.array(psnr)\n",
    "    return (~np.isinf(psrn)).sum()\n",
    "\n",
    "def get_quantile_decomp(psnr):\n",
    "    psnr = np.array(psnr)\n",
    "    psnr = psnr[~np.isinf(psnr)]\n",
    "    median = np.median(psnr)\n",
    "    q5 = np.quantile(psnr, .05)    \n",
    "    q95 = np.quantile(psnr, .95)\n",
    "    return median, q5, q95\n",
    "\n",
    "def print_eval_decomp_versions(**comp):\n",
    "    print(comp[\"v1\"], \" vs. \", comp[\"v2\"])\n",
    "    psnr = decompress_versions(**comp)\n",
    "    print(get_mismatching_images_decomp(psnr), \"/\", alaska.shape[0], \"mismatching images\")\n",
    "    if \"dct\" in comp:\n",
    "        print(\"DCT: \", comp[\"dct\"])\n",
    "    if \"sf\" in comp:\n",
    "        print(\"SF: \", comp[\"sf\"])\n",
    "    \n",
    "    if psnr:\n",
    "        median, q5, q95 = get_quantile_decomp(psnr) \n",
    "    print(\"median: \", median, \" q5: \", q5, \" q95: \", q95 )\n",
    "    print(f\"{comp['v1']} vs {comp['v2']} & ${get_mismatching_images_decomp(psnr)}$ & ${round(q5, 2)}$ & ${round(median, 2)}$ & ${round(q95, 2)}$ \\\\\")\n",
    "\n",
    "\n",
    "def print_eval_decomp_para(**comp):\n",
    "    if \"dct1\" in comp:\n",
    "        print(\"DCT: \", comp[\"dct1\"], \" vs. \", comp[\"dct2\"])\n",
    "    if \"qf1\" in comp:\n",
    "        print(\"QF: \", comp[\"qf1\"], \" vs. \", comp[\"qf2\"])\n",
    "    if \"flag1\" in comp:\n",
    "        print(\"FLAG: \",comp[\"flag1\"], \" vs. \", comp[\"flag2\"])\n",
    "        \n",
    "    psnr = decompress_parameters(**comp)\n",
    "    \n",
    "    print(get_mismatching_images_decomp(psnr), \"/\", alaska.shape[0], \"mismatching images\")\n",
    "    if psnr:\n",
    "        median, q5, q95 = get_quantile_decomp(psnr) \n",
    "    print(\"median: \", median, \" q5: \", q5, \" q95: \", q95 )\n",
    "    print(f\"& ${get_mismatching_images_decomp(psnr)}$ & ${round(q5, 2)}$ & ${round(median, 2)}$ & ${round(q95, 2)}$ \\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "breeding-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_versions=[{\"v1\":\"6b\", \"v2\":\"7\"},\n",
    "                 {\"v1\":\"9\", \"v2\":\"9a\"},\n",
    "                {\"v1\":\"6b\", \"v2\":\"9a\"}]\n",
    "\n",
    "decomp_versions_sf = [{ \"v1\":\"6b\",\n",
    "                    \"v2\":\"turbo210\",\n",
    "                    \"sf\": ((1,2),(1,1),(1,1))},\n",
    "                  { \"v1\":\"turbo210\",\n",
    "                    \"v2\":\"7\",\n",
    "                    \"sf\": ((1,2),(1,1),(1,1))},\n",
    "                  { \"v1\":\"9\",\n",
    "                    \"v2\":\"9a\",\n",
    "                    \"sf\": ((1,2),(1,1),(1,1))}]\n",
    "\n",
    "decomp_versions_sf_dct = [{\"v1\":\"8\",\n",
    "                       \"v2\":\"8a\",\n",
    "                       \"sf\": ((2,2),(1,1),(1,1)),\n",
    "                       \"dct\": 'JDCT_FLOAT'},\n",
    "                      {\"v1\":\"9a\",\n",
    "                       \"v2\":\"9b\",\n",
    "                       \"sf\": ((2,2),(1,1),(1,1)),\n",
    "                       \"dct\": 'JDCT_FLOAT'},\n",
    "                      {\"v1\":\"9a\",\n",
    "                       \"v2\":\"9b\",\n",
    "                       \"sf\": ((2,2),(1,1),(1,1)),\n",
    "                       \"dct\": 'JDCT_IFAST'}]\n",
    "all_decomp_versions = [decomp_versions, decomp_versions_sf, decomp_versions_sf_dct]\n",
    "\n",
    "\n",
    "decomp_para_dct = [{\"v\":\"9e\",\n",
    "              \"dct1\":\"JDCT_ISLOW\",\n",
    "              \"dct2\":\"JDCT_IFAST\"},\n",
    "                   {\"v\":\"9e\",\n",
    "              \"dct1\":\"JDCT_ISLOW\",\n",
    "              \"dct2\":\"JDCT_FLOAT\"},\n",
    "                  {\"v\":\"9e\",\n",
    "              \"dct1\":\"JDCT_IFAST\",\n",
    "              \"dct2\":\"JDCT_FLOAT\"}]\n",
    "decomp_para_qf = [{\"v\":\"9e\",\n",
    "              \"qf1\":\"75\",\n",
    "              \"qf2\":\"90\"},\n",
    "            {\"v\":\"9e\",\n",
    "              \"qf1\":\"90\",\n",
    "              \"qf2\":\"95\"},\n",
    "                 {\"v\":\"9e\",\n",
    "              \"qf1\":\"95\",\n",
    "              \"qf2\":\"100\"}]\n",
    "decomp_para_flag = [{\"v\":\"9e\",\n",
    "              \"flag1\":\"-DO_FANCY_UPSAMPLING\",\n",
    "              \"flag2\":\"+DO_FANCY_UPSAMPLING\"}]\n",
    "\n",
    "# all_decomp_para = [decomp_para_dct, decomp_para_qf, decomp_para_flag]\n",
    "all_decomp_para = [decomp_para_dct, decomp_para_qf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collective-request",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECOMPRESSION VERSIONS\n",
      "-----------------------------------------------\n",
      "6b  vs.  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-1b011ea693a2>:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.log10(maxi**2/mse)*10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992 / 1000 mismatching images\n",
      "median:  48.5536947017925  q5:  39.57174655086412  q95:  58.09277975835018\n",
      "6b vs 7 & $992$ & $39.57$ & $48.55$ & $58.09$ \\\n",
      "\n",
      "\n",
      "9  vs.  9a\n",
      "248 / 1000 mismatching images\n",
      "median:  92.03591546276344  q5:  80.24493521484736  q95:  101.06681533268286\n",
      "9 vs 9a & $248$ & $80.24$ & $92.04$ & $101.07$ \\\n",
      "\n",
      "\n",
      "6b  vs.  9a\n",
      "992 / 1000 mismatching images\n",
      "median:  48.5536947017925  q5:  39.57177050364372  q95:  58.09277975835018\n",
      "6b vs 9a & $992$ & $39.57$ & $48.55$ & $58.09$ \\\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "6b  vs.  turbo210\n",
      "993 / 1000 mismatching images\n",
      "SF:  ((1, 2), (1, 1), (1, 1))\n",
      "median:  49.139036926873715  q5:  38.481113775892  q95:  60.29469493120001\n",
      "6b vs turbo210 & $993$ & $38.48$ & $49.14$ & $60.29$ \\\n",
      "\n",
      "\n",
      "turbo210  vs.  7\n",
      "993 / 1000 mismatching images\n",
      "SF:  ((1, 2), (1, 1), (1, 1))\n",
      "median:  50.89464522101735  q5:  41.23828832846785  q95:  61.29701105781035\n",
      "turbo210  vs  7  & $ 50.89 $ & $ 993 $ & $ 41.24 $, $ 61.3 $ \\\n",
      "\n",
      "\n",
      "9  vs.  9a\n",
      "280 / 1000 mismatching images\n",
      "SF:  ((1, 2), (1, 1), (1, 1))\n",
      "median:  92.61583520988998  q5:  81.30944784438151  q95:  101.06681533268288\n",
      "9  vs  9a  & $ 92.62 $ & $ 280 $ & $ 81.31 $, $ 101.07 $ \\\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "8  vs.  8a\n",
      "990 / 1000 mismatching images\n",
      "DCT:  JDCT_FLOAT\n",
      "SF:  ((2, 2), (1, 1), (1, 1))\n",
      "median:  59.31039297462993  q5:  57.21099401573649  q95:  69.11870341511435\n",
      "8  vs  8a  & $ 59.31 $ & $ 990 $ & $ 57.21 $, $ 69.12 $ \\\n",
      "\n",
      "\n",
      "9a  vs.  9b\n",
      "712 / 1000 mismatching images\n",
      "DCT:  JDCT_FLOAT\n",
      "SF:  ((2, 2), (1, 1), (1, 1))\n",
      "median:  93.28530295827628  q5:  90.27500300163646  q95:  96.29560291491609\n",
      "9a  vs  9b  & $ 93.29 $ & $ 712 $ & $ 90.28 $, $ 96.3 $ \\\n",
      "\n",
      "\n",
      "9a  vs.  9b\n",
      "1000 / 1000 mismatching images\n",
      "DCT:  JDCT_IFAST\n",
      "SF:  ((2, 2), (1, 1), (1, 1))\n",
      "median:  51.16398207300006  q5:  51.11980871016319  q95:  51.995215035968975\n",
      "9a  vs  9b  & $ 51.16 $ & $ 1000 $ & $ 51.12 $, $ 52.0 $ \\\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DECOMPRESSION VERSIONS\")\n",
    "for comparisons in all_decomp_versions:\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for comp in comparisons:\n",
    "        print_eval_decomp_versions(**comp)\n",
    "        print(\"\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "DECOMPRESSION PARAMETERS\n",
      "-----------------------------------------------\n",
      "DCT:  JDCT_ISLOW  vs.  JDCT_IFAST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/630hr2nx5d3b40lh2zrf65w80000gn/T/ipykernel_21319/293968784.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.log10(maxi**2/mse)*10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 / 1000 mismatching images\n",
      "median:  58.83939070184671  q5:  56.147529006218335  q95:  63.06159198766774\n",
      " & $ 999 $ & $ 56.15 $ & $ 58.84 $, $ 63.06 $ \\\n",
      "\n",
      "\n",
      "DCT:  JDCT_ISLOW  vs.  JDCT_FLOAT\n",
      "999 / 1000 mismatching images\n",
      "median:  66.88546047786039  q5:  65.65314780381381  q95:  69.97102999306885\n",
      " & $ 999 $ & $ 65.65 $ & $ 66.89 $, $ 69.97 $ \\\n",
      "\n",
      "\n",
      "DCT:  JDCT_IFAST  vs.  JDCT_FLOAT\n",
      "999 / 1000 mismatching images\n",
      "median:  58.9149357671414  q5:  56.202810140126765  q95:  63.21615599900598\n",
      " & $ 999 $ & $ 56.2 $ & $ 58.91 $, $ 63.22 $ \\\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "QF:  75  vs.  90\n",
      "1000 / 1000 mismatching images\n",
      "median:  34.88032295018609  q5:  27.77764772049858  q95:  42.67130199023175\n",
      " & $ 1000 $ & $ 27.78 $ & $ 34.88 $, $ 42.67 $ \\\n",
      "\n",
      "\n",
      "QF:  90  vs.  95\n",
      "1000 / 1000 mismatching images\n",
      "median:  36.6045491261398  q5:  30.316648415336537  q95:  44.764280872755464\n",
      " & $ 1000 $ & $ 30.32 $ & $ 36.6 $, $ 44.76 $ \\\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(\"\\n\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"DECOMPRESSION PARAMETERS\")\n",
    "for comparisons in all_decomp_para:\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for comp in comparisons:\n",
    "        print_eval_decomp_para(**comp)\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3cc7f",
   "metadata": {},
   "source": [
    "For comparison, we look at PSNR between different DCT methods - islow and ifast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa3d3d",
   "metadata": {},
   "source": [
    "## COMPRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825659af",
   "metadata": {},
   "source": [
    "For quantification of compression mismatch we use % of match in DCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brown-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCT_match_nz(dct1, dct2):\n",
    "    (Y1,CbCr1),(Y2,CbCr2) = dct1,dct2\n",
    "    dY = (Y1[Y1 != 0] == Y2[Y1 != 0]).sum()\n",
    "    dCbCr = (CbCr1[CbCr1 != 0] == CbCr2[CbCr1 != 0]).sum()\n",
    "    # % of matched DCT coefficients (Y + CbCr)\n",
    "    return (dY + dCbCr) / ((Y1 != 0).sum() + (CbCr1 != 0).sum())\n",
    "\n",
    "def DCT_match_log(dct1, dct2):\n",
    "    (Y1,CbCr1),(Y2,CbCr2) = dct1,dct2\n",
    "    dY = (Y1 != Y2).sum()\n",
    "    dCbCr = (CbCr1 != CbCr2).sum()\n",
    "    # % of matched DCT coefficients (Y + CbCr)\n",
    "    match_pct =  (dY + dCbCr) / (Y1.size + CbCr1.size) \n",
    "    return np.log10(match_pct)\n",
    "\n",
    "def get_missing_img_comp(match):\n",
    "    match = np.array(match)\n",
    "    return np.isnan(match)\n",
    "\n",
    "def get_mismatching_img_comp(match):\n",
    "    return (~np.isinf(match))\n",
    "\n",
    "def get_quantile_comp(match):\n",
    "    return np.quantile(match, [.5, .05,.95])\n",
    "\n",
    "def print_evaluation_comp_version(**comp):\n",
    "    print(comp[\"v1\"], \" vs. \", comp[\"v2\"])\n",
    "    \n",
    "    nz_match, log_match = compression_versions(**comp)\n",
    "    matches = [nz_match, log_match]\n",
    "    \n",
    "    print_var = [\"NZ\", \"LOG\"]\n",
    "    for i, match in enumerate(matches):\n",
    "        if match:\n",
    "            median, q5, q95 = get_quantile_comp(match) \n",
    "        print(print_var[i])\n",
    "        print(get_missing_img_comp(match).sum(), \"/\", alaska.shape[0], \"missing images\")\n",
    "        print(get_mismatching_img_comp(match).sum(), \"/\", alaska.shape[0], \"mismatching images\")\n",
    "        print(\"median: \", median, \" q5: \", q5, \" q95: \", q95 )\n",
    "        print(f\"{comp['v1']} vs {comp['v2']} & ${get_mismatching_img_comp(match).sum()}$ & ${round(q5, 2)}$ & ${round(median, 2)}$ & ${round(q95, 2)}$ \\\\\")\n",
    "\n",
    "        \n",
    "def print_evaluation_comp_para(**comp):\n",
    "    if \"dct1\" in comp:\n",
    "        print(\"DCT: \", comp[\"dct1\"], \" vs. \", comp[\"dct2\"])\n",
    "    if \"qf1\" in comp:\n",
    "        print(\"QF: \", comp[\"qf1\"], \" vs. \", comp[\"qf2\"])\n",
    "    if \"flag1\" in comp:\n",
    "        print(\"FLAG: \",comp[\"flag1\"], \" vs. \", comp[\"flag2\"] if comp[\"flag2\"] is not None else \"<empty>\")\n",
    "    \n",
    "    nz_match, log_match = compression_parameters(**comp)\n",
    "    matches = [nz_match, log_match]\n",
    "    \n",
    "    print_var = [\"NZ\", \"LOG\"]\n",
    "    for i, match in enumerate(matches):\n",
    "        if match:\n",
    "            median, q5, q95 = get_quantile_comp(match) \n",
    "        print(print_var[i])\n",
    "        print(get_missing_img_comp(match).sum(), \"/\", alaska.shape[0], \"missing images\")\n",
    "        print(get_mismatching_img_comp(match).sum(), \"/\", alaska.shape[0], \"mismatching images\")\n",
    "        print(\" q5: \", q5, \"median: \", median, \" q95: \", q95 )\n",
    "        print(f\"& ${get_mismatching_img_comp(match).sum()}$ & ${round(q5, 2)}$ & ${round(median, 2)}$& ${round(q95, 2)}$ \\\\\")\n",
    "        \n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pleasant-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_versions(**kwargs):\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    nz_match,log_match = [],[]\n",
    "    for i in range(alaska.shape[0]):\n",
    "        # compress with version 1\n",
    "        with jpeglib.version(kwargs[\"v1\"]):\n",
    "            jpeglib.JPEG().write_spatial(tmp.name, alaska[i])\n",
    "        with jpeglib.version(kwargs[\"v1\"]):\n",
    "            Y_v1,CbCr_v1,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "            \n",
    "        # compress with version 2\n",
    "        with jpeglib.version(kwargs[\"v2\"]):\n",
    "            jpeglib.JPEG().write_spatial(tmp.name, alaska[i])\n",
    "        with jpeglib.version(kwargs[\"v2\"]):\n",
    "            Y_v2,CbCr_v2,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "        \n",
    "        # compute nz match\n",
    "        nz_match.append(DCT_match_nz((Y_v1,CbCr_v1), (Y_v2,CbCr_v2)))\n",
    "        log_match.append(DCT_match_log((Y_v1,CbCr_v1), (Y_v2,CbCr_v2)))\n",
    "    \n",
    "    return nz_match,log_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surprised-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_parameters(**kwargs):\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    nz_match,log_match = [],[]\n",
    "    for i in range(alaska.shape[0]):\n",
    "        # compress with version\n",
    "        with jpeglib.version(kwargs[\"v\"]):\n",
    "            if \"qf1\" in kwargs:\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], qt=kwargs[\"qf1\"])\n",
    "                Y_v1,CbCr_v1,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], qt=kwargs[\"qf2\"])\n",
    "                Y_v2,CbCr_v2,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "                \n",
    "            if \"dct1\" in kwargs:\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], dct_method=kwargs[\"dct1\"])\n",
    "                Y_v1,CbCr_v1,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], dct_method=kwargs[\"dct2\"])\n",
    "                Y_v2,CbCr_v2,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "            \n",
    "            if \"flag1\" in kwargs:\n",
    "                flag1 = [kwargs[\"flag1\"]] if kwargs[\"flag1\"] is not None else []\n",
    "                flag2 = [kwargs[\"flag2\"]] if kwargs[\"flag2\"] is not None else []\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], flags=flag1, samp_factor=((1,2),(1,1),(1,1)))\n",
    "                Y_v1,CbCr_v1,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], flags=flag2, samp_factor=((1,2),(1,1),(1,1)))\n",
    "                Y_v2,CbCr_v2,_ = jpeglib.JPEG(tmp.name).read_dct()\n",
    "                \n",
    "        \n",
    "       \n",
    "        # compute nz match\n",
    "        nz_match.append(DCT_match_nz((Y_v1,CbCr_v1), (Y_v2,CbCr_v2)))\n",
    "        log_match.append(DCT_match_log((Y_v1,CbCr_v1), (Y_v2,CbCr_v2)))\n",
    "    \n",
    "    return nz_match,log_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "composed-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per image : log10(share of all mismatching DCT coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tamil-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_versions=[\n",
    "    {\n",
    "        \"v1\":\"6b\",\n",
    "        \"v2\":\"7\"},\n",
    "    {\n",
    "        \"v1\":\"9d\",\n",
    "        \"v2\":\"9e\"},\n",
    "    {\n",
    "        \"v1\":\"6b\",\n",
    "        \"v2\":\"9e\"}]\n",
    "\n",
    "comp_para_dct = [\n",
    "{\n",
    "    \"v\":\"9e\",\n",
    "    \"dct1\":\"JDCT_ISLOW\",\n",
    "    \"dct2\":\"JDCT_FLOAT\"    \n",
    "},\n",
    "{\n",
    "    \"v\":\"9e\",\n",
    "    \"dct1\":\"JDCT_ISLOW\",\n",
    "    \"dct2\":\"JDCT_IFAST\"    \n",
    "}]\n",
    "comp_para_qf = [{\"v\":\"9e\",\n",
    "              \"qf1\":\"75\",\n",
    "              \"qf2\":\"90\"},\n",
    "            {\"v\":\"9e\",\n",
    "              \"qf1\":\"90\",\n",
    "              \"qf2\":\"95\"},\n",
    "               {\"v\":\"9e\",\n",
    "              \"qf1\":\"95\",\n",
    "              \"qf2\":\"100\"}]\n",
    "comp_para_flag = [{\"v\":\"8\",\n",
    "              \"flag1\":\"DO_FANCY_UPSAMPLING\",\n",
    "              \"flag2\":None}]#\"+DO_FANCY_UPSAMPLING\"}]\n",
    "\n",
    "all_para_compression = [comp_para_dct, comp_para_qf, comp_para_flag]\n",
    "#all_para_compression = [ comp_para_qf, comp_para_flag]\n",
    "all_versions_compression = [comp_versions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cognitive-flight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPRESSION VERSIONS\n",
      "-----------------------------------------------\n",
      "6b  vs.  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/630hr2nx5d3b40lh2zrf65w80000gn/T/ipykernel_18684/2520111299.py:14: RuntimeWarning: divide by zero encountered in log10\n",
      "  return np.log10(match_pct)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      "median:  0.996886277611759  q5:  0.9929380979820672  q95:  0.9987583524620162\n",
      "6b vs 7 & $1000$ & $0.99$ & $1.0$ & $1.0$ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "995 / 1000 mismatching images\n",
      "median:  -3.078757337295664  q5:  -3.6308433536617875  q95:  -2.6086662783180548\n",
      "6b vs 7 & $995$ & $-3.63$ & $-3.08$ & $-2.61$ \\\n",
      "\n",
      "\n",
      "9d  vs.  9e\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      "median:  0.9796591883448269  q5:  0.9359063240833658  q95:  0.9933288526340704\n",
      "9d vs 9e & $1000$ & $0.94$ & $0.98$ & $0.99$ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "995 / 1000 mismatching images\n",
      "median:  -2.474057249801493  q5:  -3.0194433360796817  q95:  -2.2833012287035497\n",
      "9d vs 9e & $995$ & $-3.02$ & $-2.47$ & $-2.28$ \\\n",
      "\n",
      "\n",
      "6b  vs.  9e\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      "median:  0.9769723860790598  q5:  0.9324504272541915  q95:  0.9922410991359658\n",
      "6b vs 9e & $1000$ & $0.93$ & $0.98$ & $0.99$ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "995 / 1000 mismatching images\n",
      "median:  -2.370876037308715  q5:  -2.8993253332032873  q95:  -2.16381485453657\n",
      "6b vs 9e & $995$ & $-2.9$ & $-2.37$ & $-2.16$ \\\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPRESSION VERSIONS\")\n",
    "for comparisons in all_versions_compression:\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for comp in comparisons:\n",
    "        print_evaluation_comp_version(**comp)\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "historic-indication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPRESSION PARAMETERS\n",
      "-----------------------------------------------\n",
      "DCT:  JDCT_ISLOW  vs.  JDCT_FLOAT\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  0.9842197522471237 median:  0.9896980705289418  q95:  0.9928846279357652\n",
      " & $ 1000 $ & $ 0.99 $ & $ 0.98 $, $ 0.99 $ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  -3.1007567808648 median:  -2.8022394915090887  q95:  -2.6766008442224627\n",
      " & $ 1000 $ & $ -2.8 $ & $ -3.1 $, $ -2.68 $ \\\n",
      "\n",
      "\n",
      "DCT:  JDCT_ISLOW  vs.  JDCT_IFAST\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  0.949619459302893 median:  0.962532380365299  q95:  0.9719488738869432\n",
      " & $ 1000 $ & $ 0.96 $ & $ 0.95 $, $ 0.97 $ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  -2.396029137742964 median:  -2.153093142305182  q95:  -2.0075043328713496\n",
      " & $ 1000 $ & $ -2.15 $ & $ -2.4 $, $ -2.01 $ \\\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "QF:  75  vs.  90\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  0.07040912338142837 median:  0.08913764527862376  q95:  0.1327664531784639\n",
      " & $ 1000 $ & $ 0.09 $ & $ 0.07 $, $ 0.13 $ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  -0.9893692838602526 median:  -0.6317035090797141  q95:  -0.36323876998885724\n",
      " & $ 1000 $ & $ -0.63 $ & $ -0.99 $, $ -0.36 $ \\\n",
      "\n",
      "\n",
      "QF:  90  vs.  95\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  0.1580758372345927 median:  0.18947741674674262  q95:  0.2562153705247136\n",
      " & $ 1000 $ & $ 0.19 $ & $ 0.16 $, $ 0.26 $ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  -0.8309501782392087 median:  -0.5227639080250379  q95:  -0.2836567983084823\n",
      " & $ 1000 $ & $ -0.52 $ & $ -0.83 $, $ -0.28 $ \\\n",
      "\n",
      "\n",
      "QF:  95  vs.  100\n",
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  0.14081517768625396 median:  0.25594417092634114  q95:  0.5305139042043361\n",
      " & $ 1000 $ & $ 0.26 $ & $ 0.14 $, $ 0.53 $ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  -0.37442474998896097 median:  -0.1426361027688192  q95:  -0.06806757944484117\n",
      " & $ 1000 $ & $ -0.14 $ & $ -0.37 $, $ -0.07 $ \\\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "FLAG:  DO_FANCY_UPSAMPLING  vs.  <empty>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/630hr2nx5d3b40lh2zrf65w80000gn/T/ipykernel_18684/2520111299.py:14: RuntimeWarning: divide by zero encountered in log10\n",
      "  return np.log10(match_pct)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NZ\n",
      "0 / 1000 missing images\n",
      "1000 / 1000 mismatching images\n",
      " q5:  1.0 median:  1.0  q95:  1.0\n",
      " & $ 1000 $ & $ 1.0 $ & $ 1.0 $, $ 1.0 $ \\\n",
      "LOG\n",
      "0 / 1000 missing images\n",
      "0 / 1000 mismatching images\n",
      " q5:  -inf median:  -inf  q95:  -inf\n",
      " & $ 0 $ & $ -inf $ & $ -inf $, $ -inf $ \\\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"COMPRESSION PARAMETERS\")\n",
    "for comparisons in all_para_compression:\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for comp in comparisons:\n",
    "        print_evaluation_comp_para(**comp)\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-norwegian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-latex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-lightweight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "frequent-application",
   "metadata": {},
   "source": [
    "## Old experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for experiments\n",
    "def compression_test(versions, flag):\n",
    "    images_rgb = {'version': [], 'image': [], 'dct': []}\n",
    "    kw = {'qt': 75, 'in_color_space': 'JCS_RGB', 'flags': [flag]}\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        for e, v_compress in enumerate(versions):\n",
    "            \n",
    "            # compress with each version\n",
    "            fnames = [str(Path(tmp) / f'{i}.jpeg') for i in range(alaska.shape[0])]\n",
    "            with jpeglib.version(v_compress):\n",
    "                [jpeglib.JPEG().write_spatial(fname, alaska[i], **kw) for i,fname in enumerate(fnames)] \n",
    "            \n",
    "            # decompress with single (arbitrary) version\n",
    "            with jpeglib.version(v_arbitrary):\n",
    "                images_rgb['version'].append(v_compress)\n",
    "                images_rgb['image'].append(np.array([\n",
    "                    jpeglib.JPEG(fname).read_spatial(flags=[flag]) for fname in fnames\n",
    "                ]))\n",
    "                images_rgb['dct'].append([\n",
    "                    jpeglib.JPEG(fname).read_dct() for fname in fnames\n",
    "                ])\n",
    "                \n",
    "    return pd.DataFrame(images_rgb)\n",
    "\n",
    "def decompression_test(versions, flag):\n",
    "    images_rgb = {'version': [], 'image': []}\n",
    "    kw = {'qt': 75, 'in_color_space': 'JCS_RGB', 'flags': [flag]}\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        for e, v_decompress in enumerate(versions):\n",
    "            \n",
    "            # compress with single (arbitrary) version\n",
    "            fnames = [str(Path(tmp) / f'{i}.jpeg') for i in range(alaska.shape[0])]\n",
    "            with jpeglib.version(v_arbitrary):\n",
    "                [jpeglib.JPEG().write_spatial(fname, alaska[i], **kw) for i,fname in enumerate(fnames)]\n",
    "            \n",
    "            # decompress with each version\n",
    "            with jpeglib.version(v_decompress):\n",
    "                images_rgb['version'].append(v_decompress)\n",
    "                images_rgb['image'].append(np.array([\n",
    "                    jpeglib.JPEG(fname).read_spatial(flags=[flag]) for fname in fnames\n",
    "                ]))\n",
    "                \n",
    "    return pd.DataFrame(images_rgb)  \n",
    "\n",
    "def fancy_upsampling_test(versions, flag):\n",
    "    # sampling factor\n",
    "    samp_factors = [\n",
    "        ((1,1),(1,1),(1,1)), # 4:4:4\n",
    "        ((1,2),(1,2),(1,2)),\n",
    "        ((2,1),(2,1),(2,1)),\n",
    "\n",
    "        ((1,2),(1,1),(1,1)), # 4:4:0\n",
    "        ((2,2),(2,1),(2,1)),\n",
    "        ((1,4),(1,2),(1,2)),\n",
    "        ((1,2),(1,2),(1,1)),   # Cb 4:4:4 Cr 4:4:0\n",
    "        ((1,2),(1,1),(1,2)),   # Cb 4:4:0 Cr 4:4:4\n",
    "\n",
    "        ((2,1),(1,1),(1,1)), # 4:2:2\n",
    "        ((2,2),(1,2),(1,2)),\n",
    "        ((2,1),(2,1),(1,1)),   # Cb 4:4:4 Cr 4:2:2\n",
    "        ((2,1),(1,1),(2,1)),   # Cb 4:2:2 Cr 4:4:4\n",
    "\n",
    "        ((2,2),(1,1),(1,1)), # 4:2:0\n",
    "        ((2,2),(2,1),(1,1)),   # Cb 4:4:0 Cr 4:2:0\n",
    "        ((2,2),(1,1),(2,1)),   # Cb 4:2:0 Cr 4:4:0\n",
    "        ((2,2),(1,2),(1,1)),   # Cb 4:2:2 Cr 4:2:0\n",
    "        ((2,2),(1,1),(1,2)),   # Cb 4:2:0 Cr 4:2:2\n",
    "        ((2,2),(2,2),(1,1)),   # Cb 4:4:4 Cr 4:2:0\n",
    "        ((2,2),(2,2),(2,1)),   # Cb 4:4:4 Cr 4:4:0\n",
    "        ((2,2),(2,2),(1,2)),   # Cb 4:4:4 Cr 4:2:2\n",
    "        ((2,2),(1,1),(2,2)),   # Cb 4:2:0 Cr 4:4:4\n",
    "        ((2,2),(2,1),(2,2)),   # Cb 4:4:0 Cr 4:4:4\n",
    "        ((2,2),(1,2),(2,2)),   # Cb 4:2:2 Cr 4:4:4\n",
    "\n",
    "        ((4,1),(1,1),(1,1)), # 4:1:1\n",
    "        ((4,1),(2,1),(1,1)),   # Cb 4:2:2 Cr 4:1:1\n",
    "        ((4,1),(1,1),(2,1)),   # Cb 4:1:1 Cr 4:2:2\n",
    "\n",
    "        ((4,2),(1,1),(1,1)), # 4:1:0\n",
    "\n",
    "        ((1,4),(1,1),(1,1)), # 1:0.5:0\n",
    "        ((1,4),(1,2),(1,1)),\n",
    "\n",
    "        ((2,4),(1,1),(1,1)), # 2:0.5:0\n",
    "\n",
    "        ((3,1),(1,1),(1,1)), # 3:1:1\n",
    "        ((3,1),(3,1),(1,1)),   # Cb 4:4:4 Cr 3:1:1\n",
    "        ((3,1),(1,1),(3,1)),   # Cb 3:1:1 Cr 4:4:4\n",
    "    ]\n",
    "\n",
    "    images_rgb_cdFU = {'version': [], 'samp_factor': [], 'dct': [], 'image': []}\n",
    "    kw = {'qt': 75, 'flags': [flag], 'in_color_space': 'JCS_RGB'}\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "    \n",
    "        # iterate versions\n",
    "        for i,v_decompress in enumerate(versions):\n",
    "\n",
    "            # iterate samp factors\n",
    "            for samp_factor in samp_factors:\n",
    "\n",
    "                # compress each image with version\n",
    "                fnames = [str(Path(tmp) / f'{i}.jpeg') for i in range(alaska.shape[0])]\n",
    "                with jpeglib.version(v_arbitrary):\n",
    "                    [jpeglib.JPEG().write_spatial(fname, alaska[i], samp_factor=samp_factor, **kw)\n",
    "                         for i,fname in enumerate(fnames)]\n",
    "\n",
    "                # decompress with single (arbitrary) version\n",
    "                with jpeglib.version(v_decompress):\n",
    "                    images_rgb_cdFU['version'].append(v_decompress)\n",
    "                    images_rgb_cdFU['samp_factor'].append(samp_factor)\n",
    "                    images_rgb_cdFU['image'].append(np.array([\n",
    "                        jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames\n",
    "                    ]))\n",
    "                    images_rgb_cdFU['dct'].append([\n",
    "                        jpeglib.JPEG(fname).read_dct() for fname in fnames\n",
    "                    ])\n",
    "\n",
    "    return pd.DataFrame(images_rgb_cdFU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-coffee",
   "metadata": {},
   "source": [
    "# Vizualisation of the differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-fluid",
   "metadata": {},
   "source": [
    "Here you can see how much the values differ for all combinations of produced clusters per experiment.\n",
    "\n",
    "We vizualize 13 histograms in total:\n",
    "### Baseline Compression\n",
    "- (6b + 7), (6b + 9e), (7 + 9e)\n",
    "\n",
    "### Baseline Decompression\n",
    "- (6b + 7), (6b + 9a), (7 + 9a)\n",
    "\n",
    "### Simple Upscaling\n",
    "- (6b + 9a)\n",
    "\n",
    "### Fancy Upsampling\n",
    "- (6b + turbo), (6b + 7), (6b + 9a), (turbo210 + 7), (turbo210 + 9a), (7 + 9a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions Vizualisation\n",
    "\n",
    "def get_images_of_versions(images, versions):\n",
    "    (imageV1,) = images[images.version == versions[0]].image\n",
    "    (imageV2,) = images[images.version == versions[1]].image\n",
    "    return (imageV1.astype(np.int32) - imageV2.astype(np.int32))\n",
    "\n",
    "def plot_histogram(D, version, title):\n",
    "    fig,ax = plt.subplots(1,1, figsize=[12,7], sharey=True)\n",
    "    #fig.subtitle(f'Distribution of differences for {versions}', fontsize=11)\n",
    "    \n",
    "    sns.set_theme()\n",
    "    sns.despine(left=False, bottom=False)\n",
    "    g = sns.histplot(D.flatten(), ax=ax, binwidth=1., stat='density')\n",
    "    g.set_yscale('log');\n",
    "    plot_path = path.join('..', 'text', 'forensic', 'figures', f'histogram_{title}_{version}.png')\n",
    "    plt.savefig(plot_path);\n",
    "\n",
    "def compare_and_plot_subplots(images, versions, title):\n",
    "    fig,axs = plt.subplots(1,len(versions), figsize=(16,4), sharey=True)\n",
    "    #fig.title(f'Distribution of differences for {title}', fontsize=14)\n",
    "    \n",
    "    for k, v1 in enumerate(versions):\n",
    "        for v2 in versions[k:]:\n",
    "            if v1 == v2:\n",
    "                continue\n",
    "            D = get_images_of_versions(images, [v1, v2])\n",
    "            \n",
    "            p = sns.histplot(D.flatten(), binwidth=1, ax=axs[k])\n",
    "            p.set_title(f'{v1} - {v2}', fontsize=8)\n",
    "            plot_path = path.join('..', 'text', 'forensic', 'figures', f'histogram_{title}_{v1}_{v2}.png')\n",
    "            print(\"saving plot for \", title, \" \", v1, \" - \", v2)\n",
    "            plt.savefig(plot_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-bernard",
   "metadata": {},
   "source": [
    "## Baseline Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ['6b','7', '9e']\n",
    "title = \"BaselineCompression\"\n",
    "flag = 'DO_FANCY_UPSAMPLING'\n",
    "images = compression_test(versions, flag)\n",
    "\n",
    "# generate plot for all unique version combinations\n",
    "# compare_and_plot_subplots(images, versions, title)\n",
    "plot_histogram(images, ['6b', '9a'], title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-meditation",
   "metadata": {},
   "source": [
    "## Baseline Decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ['6b','7', '9a']\n",
    "title = \"BaselineDecompression\"\n",
    "flag = 'DO_FANCY_UPSAMPLING'\n",
    "images = decompression_test(versions, flag)\n",
    "\n",
    "# generate plot for all unique version combinations\n",
    "compare_and_plot_subplots(images, versions, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-inclusion",
   "metadata": {},
   "source": [
    "## Fancy Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e299c93",
   "metadata": {},
   "source": [
    "### Factor 4:4:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'samp_factor': ((1,2),(1,1),(1,1))}\n",
    "tmp = tempfile.TemporaryDirectory()\n",
    "    \n",
    "# compress image\n",
    "fnames = [str(Path(tmp.name) / f'{i}.jpeg') for i in range(alaska.shape[0])]\n",
    "with jpeglib.version(v_arbitrary):\n",
    "    [jpeglib.JPEG().write_spatial(fname, alaska[i], **kw) for i,fname in enumerate(fnames)]\n",
    "\n",
    "# decompress with each version\n",
    "with jpeglib.version('6b'):\n",
    "    x_6b = np.array([jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames])\n",
    "with jpeglib.version('turbo210'):\n",
    "    x_turbo = np.array([jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames])\n",
    "\n",
    "# compute the difference\n",
    "D_fu440_6b_turbo = x_6b.astype(np.int32) - x_turbo.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d650bce",
   "metadata": {},
   "source": [
    "### Factor 4:2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'samp_factor': ((2,1),(1,1),(1,1))}\n",
    "tmp = tempfile.TemporaryDirectory()\n",
    "    \n",
    "# compress image\n",
    "fnames = [str(Path(tmp.name) / f'{i}.jpeg') for i in range(alaska.shape[0])]\n",
    "with jpeglib.version(v_arbitrary):\n",
    "    [jpeglib.JPEG().write_spatial(fname, alaska[i], **kw) for i,fname in enumerate(fnames)]\n",
    "\n",
    "# decompress with each version\n",
    "with jpeglib.version('6b'):\n",
    "    x_6b = np.array([jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames])\n",
    "with jpeglib.version('7'):\n",
    "    x_7 = np.array([jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames])\n",
    "\n",
    "# compute the difference\n",
    "D_fu422_6b_7 = x_6b.astype(np.int32) - x_turbo.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce plot\n",
    "#fig,ax = plt.subplots(1,1, figsize=[12,7], sharey=True)\n",
    "#sns.set_theme()\n",
    "#sns.despine(left=False, bottom=False)\n",
    "#g = sns.histplot(D_440_6b_turbo.flatten(), ax=ax, binwidth=1., stat='density')\n",
    "#g.set_yscale('log');\n",
    "#g.set_xlabel('Difference')\n",
    "#plot_path = path.join('..', 'text', 'forensic', 'figures', 'histogram_4:4:0_6b-turbo.png')\n",
    "#plt.savefig(plot_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-paraguay",
   "metadata": {},
   "source": [
    "## DCT method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae757f38",
   "metadata": {},
   "source": [
    "To compare the differences produced by differing versions, we now look at the differences, that different DCT methods produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10926e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'flags': ['DO_FANCY_UPSAMPLING']}\n",
    "tmp = tempfile.TemporaryDirectory()\n",
    "    \n",
    "# compress image with islow\n",
    "fnames = [str(Path(tmp.name) / f'{i}.jpeg') for i in range(alaska.shape[0])]\n",
    "[jpeglib.JPEG().write_spatial(fname, alaska[i], dct_method='JDCT_ISLOW', **kw) for i,fname in enumerate(fnames)]\n",
    "x_islow = np.array([jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames])\n",
    "\n",
    "# compress image with ifast\n",
    "[jpeglib.JPEG().write_spatial(fname, alaska[i], dct_method='JDCT_IFAST', **kw) for i,fname in enumerate(fnames)]\n",
    "x_ifast = np.array([jpeglib.JPEG(fname).read_spatial(flags=['DO_FANCY_UPSAMPLING']) for fname in fnames])\n",
    "\n",
    "# compute difference\n",
    "D_islow_ifast = x_islow.astype(np.int32) - x_ifast.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598609b",
   "metadata": {},
   "source": [
    "## Violin plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c83968",
   "metadata": {},
   "source": [
    "At last we create a violin plot presenting the complete picture, compared to different DCT methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        'Scenario': '6b-turbo\\nfancy upsampling 4:4:0',\n",
    "        'Difference': D_fu440_6b_turbo[D_fu440_6b_turbo != 0].flatten()\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        'Scenario': '6b-7\\nfancy upsampling 4:2:2',\n",
    "        'Difference': D_fu422_6b_7[D_fu422_6b_7 != 0].flatten()\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        'Scenario': 'islow-ifast',\n",
    "        'Difference': D_islow_ifast[D_islow_ifast != 0].flatten()\n",
    "    })\n",
    "])\n",
    "fig,ax = plt.subplots(1,1, figsize=[12,7], sharey=True)\n",
    "sns.violinplot(x='Scenario', y='Difference', bw=.12, data=df, ax=ax, cut=0)\n",
    "plt.ylim(-17, 17);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-addiction",
   "metadata": {},
   "source": [
    "# PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05916bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(x_ref, x_noisy):\n",
    "    D = x_ref.astype(np.float32) - x_noisy.astype(np.float32)\n",
    "    mse = (D**2).mean(axis=tuple(range(1,len(x_ref.shape))))\n",
    "    maxi = x_ref.max(axis=tuple(range(1,len(x_ref.shape)))).astype(np.float64)\n",
    "    return np.log10(maxi**2/mse)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12900f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alaska.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c943705",
   "metadata": {},
   "source": [
    "### 6b-7 compression 4:2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for v in ['6b','7']:\n",
    "    x_fu_422 = []\n",
    "    # recompress\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version(v):\n",
    "            jpeglib.JPEG().write_spatial(\n",
    "                tmp.name, alaska[i],\n",
    "                dct_method='JDCT_ISLOW', flags=['DO_FANCY_UPSAMPLING'], samp_factor=((2,1),(1,1),(1,1))\n",
    "            )\n",
    "        with jpeglib.version('6b'):\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "        x_fu_422.append(x)\n",
    "\n",
    "    # substract mode\n",
    "    #Y_fu_422 = np.array(Y_fu_422) - stats.mode(Y_fu_422, axis=0)[0]\n",
    "    #CbCr_fu_422 = np.array(CbCr_fu_422) - stats.mode(CbCr_fu_422, axis=0)[0]\n",
    "    # compute psnr\n",
    "    #psnr_Y_fu_422 = PSNR(alaska, np.array(Y_fu_422))\n",
    "    #psnr_CbCr_fu_422 = PSNR(alaska, np.array(CbCr_fu_422))\n",
    "    #print(psnr_Y_fu_422.shape, psnr_CbCr_fu_422.shape)\n",
    "    psnr_fu_422 = PSNR(alaska, np.array(x_fu_422))\n",
    "    print(\"6b-7 compression\", v, psnr_fu_422.mean(), psnr_fu_422.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55307945",
   "metadata": {},
   "source": [
    "### 6b-7 decompression 4:2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237bb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for v in ['6b','7']:\n",
    "    x_fu_422 = []\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version('6b'):\n",
    "            jpeglib.JPEG().write_spatial(tmp.name, alaska[i],\n",
    "                                         dct_method='JDCT_ISLOW',\n",
    "                                         flags=['DO_FANCY_UPSAMPLING'],\n",
    "                                         samp_factor=((2,1),(1,1),(1,1)))\n",
    "        with jpeglib.version(v):\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "        x_fu_422.append(x)\n",
    "    # compute psnr\n",
    "    psnr_fu_422 = PSNR(alaska, np.array(x_fu_422))\n",
    "    print(\"FU\", \"4:2:2\", v, psnr_fu_422.mean(), psnr_fu_422.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6c878",
   "metadata": {},
   "source": [
    "### 6b-turbo decompression 4:4:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ace9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for v in ['6b','turbo210']:\n",
    "    x_fu_440 = []\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version('6b'):\n",
    "            jpeglib.JPEG().write_spatial(tmp.name, alaska[i],\n",
    "                                         dct_method='JDCT_ISLOW',\n",
    "                                         flags=['DO_FANCY_UPSAMPLING'],\n",
    "                                         samp_factor=((1,2),(1,1),(1,1)))\n",
    "        with jpeglib.version(v):\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "        x_fu_440.append(x)\n",
    "    # compute psnr\n",
    "    psnr_fu_440 = PSNR(alaska, np.array(x_fu_440))\n",
    "    print(\"FU\", \"4:2:2\", v, psnr_fu_440.mean(), psnr_fu_440.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e49a04",
   "metadata": {},
   "source": [
    "### 9-9a decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for v in ['9','9a']:\n",
    "    x_9_9a = []\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version('9'):\n",
    "            jpeglib.JPEG().write_spatial(tmp.name, alaska[i],\n",
    "                                         dct_method='JDCT_ISLOW',\n",
    "                                         flags=['DO_FANCY_UPSAMPLING'],\n",
    "                                         samp_factor=((1,1),(1,1),(1,1)))\n",
    "        with jpeglib.version(v):\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial()\n",
    "        x_9_9a.append(x)\n",
    "    # compute psnr\n",
    "    psnr_9_9a = PSNR(alaska, np.array(x_9_9a))\n",
    "    print(\"9-9a\", v, psnr_9_9a.mean(), psnr_9_9a.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e028e3",
   "metadata": {},
   "source": [
    "### 9d-9e compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45410d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for v in ['9d','9e']:\n",
    "    x_9d_9e = []\n",
    "    # recompress\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version(v):\n",
    "            jpeglib.JPEG().write_spatial(\n",
    "                tmp.name, alaska[i],\n",
    "                dct_method='JDCT_ISLOW', flags=['DO_FANCY_UPSAMPLING'], samp_factor=((2,1),(1,1),(1,1))\n",
    "            )\n",
    "        with jpeglib.version('9d'):\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "        x_9d_9e.append(x)\n",
    "\n",
    "    psnr_9d_9e = PSNR(alaska, np.array(x_9d_9e))\n",
    "    print(\"9d-9e compression\", v, psnr_9d_9e.mean(), psnr_9d_9e.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f8d7a",
   "metadata": {},
   "source": [
    "### Compression DCT method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for method in ['JDCT_ISLOW','JDCT_IFAST']:\n",
    "    x_islow_ifast = []\n",
    "    # recompress\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version('9d'):\n",
    "            jpeglib.JPEG().write_spatial(\n",
    "                tmp.name, alaska[i],\n",
    "                dct_method='JDCT_ISLOW', flags=['DO_FANCY_UPSAMPLING'], samp_factor=((2,1),(1,1),(1,1))\n",
    "            )\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method=method)\n",
    "        x_islow_ifast.append(x)\n",
    "\n",
    "    psnr_islow_ifast = PSNR(alaska, np.array(x_islow_ifast))\n",
    "    print(\"islow-ifast compression\", method, psnr_islow_ifast.mean(), psnr_islow_ifast.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b38c2",
   "metadata": {},
   "source": [
    "### Decompression DCT method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for method in ['JDCT_ISLOW','JDCT_IFAST']:\n",
    "    x_islow_ifast = []\n",
    "    # recompress\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version('9d'):\n",
    "            jpeglib.JPEG().write_spatial(\n",
    "                tmp.name, alaska[i],\n",
    "                dct_method=method, flags=['DO_FANCY_UPSAMPLING'], samp_factor=((2,1),(1,1),(1,1))\n",
    "            )\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "        x_islow_ifast.append(x)\n",
    "\n",
    "    psnr_islow_ifast = PSNR(alaska, np.array(x_islow_ifast))\n",
    "    print(\"islow-ifast decompression\", method, psnr_islow_ifast.mean(), psnr_islow_ifast.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cfa39",
   "metadata": {},
   "source": [
    "### DCT method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "tmp = tempfile.NamedTemporaryFile() # create temporary file\n",
    "for method in ['JDCT_ISLOW','JDCT_IFAST']:\n",
    "    x_islow_ifast = []\n",
    "    # recompress\n",
    "    for i in range(alaska.shape[0]):\n",
    "        with jpeglib.version('9d'):\n",
    "            jpeglib.JPEG().write_spatial(\n",
    "                tmp.name, alaska[i],\n",
    "                dct_method=method, flags=['DO_FANCY_UPSAMPLING'], samp_factor=((2,1),(1,1),(1,1))\n",
    "            )\n",
    "            x = jpeglib.JPEG(tmp.name).read_spatial(dct_method=method)\n",
    "        x_islow_ifast.append(x)\n",
    "\n",
    "    psnr_islow_ifast = PSNR(alaska, np.array(x_islow_ifast))\n",
    "    print(\"islow-ifast\", method, psnr_islow_ifast.mean(), psnr_islow_ifast.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cefec6d",
   "metadata": {},
   "source": [
    "### DCT method: islow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary file\n",
    "with tempfile.NamedTemporaryFile() as tmp:\n",
    "    # iterate versions\n",
    "    for v in ['6b', 'turbo210', '7', '9a', '9e']:\n",
    "        with jpeglib.version(v):\n",
    "            \n",
    "            # compress ifast\n",
    "            x_ifast = []\n",
    "            for i in range(alaska.shape[0]):\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], dct_method='JDCT_IFAST', samp_factor=((1,1),(1,1),(1,1)))\n",
    "                x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_IFAST')\n",
    "                x_ifast.append(x)\n",
    "            # compute psnr\n",
    "            psnr_ifast = PSNR(alaska, np.array(x_ifast))\n",
    "            print(\"ifast\", v, psnr_ifast.mean(), psnr_ifast.std())\n",
    "            \n",
    "            # compress islow\n",
    "            x_islow = []\n",
    "            for i in range(alaska.shape[0]):\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], dct_method='JDCT_ISLOW', samp_factor=((1,1),(1,1),(1,1)))\n",
    "                x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "                x_islow.append(x)\n",
    "            # compute psnr\n",
    "            psnr_islow = PSNR(alaska, np.array(x_islow))\n",
    "            print(\"islow\", v, psnr_islow.mean(), psnr_islow.std())\n",
    "            \n",
    "            # compress FU 4:2:2\n",
    "            x_fu_422 = []\n",
    "            for i in range(alaska.shape[0]):\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], dct_method='JDCT_ISLOW', flags=['DO_FANCY_UPSAMPLING'], samp_factor=((2,1),(1,1),(1,1)))\n",
    "                x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "                x_fu_422.append(x)\n",
    "            # compute psnr\n",
    "            psnr_islow = PSNR(alaska, np.array(x_fu_422))\n",
    "            print(\"FU4:2:2\", v, psnr_islow.mean(), psnr_islow.std())\n",
    "            \n",
    "            # compress FU 4:4:0\n",
    "            x_fu_440 = []\n",
    "            for i in range(alaska.shape[0]):\n",
    "                jpeglib.JPEG().write_spatial(tmp.name, alaska[i], dct_method='JDCT_ISLOW', flags=['DO_FANCY_UPSAMPLING'], samp_factor=((1,2),(1,1),(1,1)))\n",
    "                x = jpeglib.JPEG(tmp.name).read_spatial(dct_method='JDCT_ISLOW')\n",
    "                x_fu_440.append(x)\n",
    "            # compute psnr\n",
    "            psnr_islow = PSNR(alaska, np.array(x_fu_440))\n",
    "            print(\"FU4:4:0\", v, psnr_islow.mean(), psnr_islow.std())\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psnr ifast\n",
    "psnr_ifast = {v: PSNR(img, x_ifast[v]) for v in versions}\n",
    "#psnr_ifast_6b = PSNR(img, x_ifast['6b'])\n",
    "print('psnr ifast: ', psnr_ifast, '\\n')\n",
    "\n",
    "# psnr islow\n",
    "#psnr_islow = PSNR(versions, img, x_islow)\n",
    "#print('psnr islow: ', psnr_islow, '\\n')\n",
    "\n",
    "# psnr fancy upsampling 4:2:2\n",
    "#psnr_fancy_us_422 = PSNR(versions, img, x_fancy_us_422)\n",
    "#print('psnr fancy upsampling 4:2:2: ', psnr_fancy_us_422, '\\n')\n",
    "\n",
    "# psnr fancy upsampling 4:4:0\n",
    "#psnr_fancy_us_440 = PSNR(versions, img, x_fancy_us_440)\n",
    "#print('psnr fancy upsampling 4:4:0: ', psnr_fancy_us_440, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998acc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_PSNR(x_ref, x_noisy):\n",
    "    D = x_ref.astype(np.float32) - x_noisy.astype(np.float32)\n",
    "    mse = (D**2).mean(axis=(0,1,2))\n",
    "    maxi = x_ref.max(axis=(0,1,2)).astype(np.float64)\n",
    "    #print(mse)\n",
    "    return np.log10(maxi**2/mse)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "# random_img = random.randrange(61600)\n",
    "# reference_image = os.path.join(alaska_path, f'{random_img}.tif})\n",
    "ref_img = os.path.join(alaska_path, \"58580.tif\")\n",
    "img = np.array(Image.open(ref_img, 'r'))\n",
    "print('Shape: ', img.shape)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(versions, kw):\n",
    "    img_comp = {}\n",
    "    for v in versions:\n",
    "        with jpeglib.version(v):\n",
    "            jpeglib.JPEG().write_spatial(ref_img, img, **kw)\n",
    "            x = np.array(jpeglib.JPEG(ref_img).read_spatial(flags=['DO_FANCY_UPSAMPLING']))\n",
    "        img_comp[v] = x\n",
    "    return img_comp\n",
    "\n",
    "def decompress(versions, kw):\n",
    "    img_decomp = {}\n",
    "    for v in versions:\n",
    "        with jpeglib.version(v):\n",
    "            jpeglib.JPEG().write_spatial(ref_img, img, **kw) \n",
    "            x = jpeglib.JPEG(ref_img).read_spatial(flags=['DO_FANCY_UPSAMPLING'])\n",
    "        img_decomp[v] = x\n",
    "    return img_decomp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ['6b', 'turbo210', '7', '9a', '9e']\n",
    "\n",
    "# compress ifast\n",
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'dct_method': 'JDCT_IFAST','flags': ['DO_FANCY_UPSAMPLING']}\n",
    "x_ifast = compress(versions, kw)\n",
    "\n",
    "# compress islow\n",
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'dct_method': 'JDCT_ISLOW','flags': ['DO_FANCY_UPSAMPLING']}\n",
    "x_islow = compress(versions, kw)\n",
    "\n",
    "# fancy upsampling 4:2:2\n",
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'flags': ['DO_FANCY_UPSAMPLING'], 'samp_factor': ((2,1),(1,1),(1,1))}\n",
    "x_fancy_us_422 = decompress(versions, kw)\n",
    "\n",
    "# fancy upsampling 4:4:0\n",
    "kw = {'qt': 75, 'flags': [], 'in_color_space': 'JCS_RGB', 'flags': ['DO_FANCY_UPSAMPLING'], 'samp_factor': ((1,2),(1,1),(1,1))}\n",
    "x_fancy_us_440 = decompress(versions, kw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psnr(versions, img, x):\n",
    "    psnr = {}\n",
    "    for v in versions:\n",
    "        psnr[v] = calc_PSNR(img, x[v])\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psnr ifast\n",
    "psnr_ifast = get_psnr(versions, img, x_ifast)\n",
    "print('psnr ifast: ', psnr_ifast, '\\n')\n",
    "\n",
    "# psnr islow\n",
    "psnr_islow = get_psnr(versions, img, x_islow)\n",
    "print('psnr islow: ', psnr_islow, '\\n')\n",
    "\n",
    "# psnr fancy upsampling 4:2:2\n",
    "psnr_fancy_us_422 = get_psnr(versions, img, x_fancy_us_422)\n",
    "print('psnr fancy upsampling 4:2:2: ', psnr_fancy_us_422, '\\n')\n",
    "\n",
    "\n",
    "# psnr fancy upsampling 4:4:0\n",
    "psnr_fancy_us_440 = get_psnr(versions, img, x_fancy_us_440)\n",
    "print('psnr fancy upsampling 4:4:0: ', psnr_fancy_us_440, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-collect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
